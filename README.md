# Databricks-Study-Materials
Data Engineering with Databricks Study Materials

Course Description
Data professionals from all walks of life will benefit from this comprehensive introduction to the components of the Databricks Lakehouse Platform that directly support putting ETL pipelines into production. Students will leverage SQL and Python to define and schedule pipelines that incrementally process new data from a variety of data sources to power analytic applications and dashboards in the Lakehouse. This course offers hands-on instruction in Databricks Data Science & Engineering Workspace, Databricks SQL, Delta Live Tables, Databricks Repos, Databricks Task Orchestration, and the Unity Catalog.



Learning objectives

    Leverage the Databricks Lakehouse Platform to perform core responsibilities for data pipeline development
    Use SQL and Python to write production data pipelines to extract, transform, and load data into tables and views in the Lakehouse
    Simplify data ingestion and incremental change propagation using Databricks-native features and syntax, including Delta Live Tables
    Orchestrate production pipelines to deliver fresh results for ad-hoc analytics and dashboarding


Prerequisites

    Work or educational experience as a data or IT professional
    Experience using SQL to query data from enterprise data stores
    Familiarity with basic cloud concepts (virtual machines, object storage, identity management)
    Basic familiarity with Python variables, functions, and control flow (preferred)

