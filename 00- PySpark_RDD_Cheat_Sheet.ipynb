{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/Databricks-Study-Materials/blob/main/00-%20PySpark_RDD_Cheat_Sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI4EaOiewCOm"
      },
      "source": [
        "### Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpxPVdHxs42M",
        "outputId": "6c3d39c7-130c-4769-9841-9491567392b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqusXdISyILc"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f36Xu4uIyKs2"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf\n",
        "conf = (SparkConf()\n",
        "                  .setMaster('local[3]')\n",
        "                  .setAppName('First App')\n",
        "                  .set('spark.executor.memory','1g'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GfU_KXTxUY9"
      },
      "source": [
        "### Initializing Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guxb_4HtxqPZ"
      },
      "outputs": [],
      "source": [
        "### Spark Context\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(conf = conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_p6s6zPwKCv"
      },
      "source": [
        "### Inspect SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VdDSi_jtvwU",
        "outputId": "be629555-4bf7-4740-f681-bfebf915e1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] 3.3.0\n",
            "[2] 3.7\n",
            "[3] local[3]\n",
            "[4] None\n",
            "[5] root\n",
            "[6] First App\n",
            "[7] local-1656579071118\n",
            "[8] 3\n",
            "[9] 2\n"
          ]
        }
      ],
      "source": [
        "print([1], sc.version)              # Retrieve SparkContext version\n",
        "print([2], sc.pythonVer)            # Retrieve Python version\n",
        "print([3], sc.master)               # Master URL to connect to\n",
        "print([4], str(sc.sparkHome))       # Path where Spark is installed on worker nodes\n",
        "print([5], str(sc.sparkUser()))     # Retrieve name of the Spark User running SparkContext\n",
        "print([6], sc.appName)              # Return application name\n",
        "print([7], sc.applicationId)        # Retrieve application ID\n",
        "print([8], sc.defaultParallelism)   # Return default level of parallelism\n",
        "print([9], sc.defaultMinPartitions) # Default minimum number of partitions forRDDs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Shell"
      ],
      "metadata": {
        "id": "UCqbgQz0k2nP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1A2y7cS4u8Jq"
      },
      "outputs": [],
      "source": [
        "# %%shell\n",
        "# pyspark --master local[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Spark Session instead Spark Context"
      ],
      "metadata": {
        "id": "e6W7-e-dk9wa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS9QSWZ90gPr"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "!ls\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallelized Collections"
      ],
      "metadata": {
        "id": "3KDvCQ9xrQlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([('x',10),('x',11),('y',10),('b',2),('c',2)])\n",
        "rdd3 = sc.parallelize(range(100))\n",
        "rdd4 = sc.parallelize([( 'a',[ 'x', 'y', 'z']),( 'b',[ 'p', 'r'])])"
      ],
      "metadata": {
        "id": "8k08AkSvlNGS"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### External Data"
      ],
      "metadata": {
        "id": "jyG43TtBsKJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textFile = sc.textFile('/my/directory/*.txt')\n",
        "textFile2 = sc.wholeTextFiles('/my/directory/')"
      ],
      "metadata": {
        "id": "greMWCQiqP3i"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving RDD information"
      ],
      "metadata": {
        "id": "s-w_Qb04sTDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.getNumPartitions()) # List the number of partitions\n",
        "print(rdd.count())            # Count RDD instances\n",
        "print(rdd.countByKey())       # Count RDD instances by key\n",
        "print(rdd.countByValue())     # Count RDD instances by value\n",
        "print(rdd.collectAsMap())     # Return (key, value) pairs as a dictionary\n",
        "print(rdd3.sum())             # Sum of RDD elements \n",
        "print(rdd.isEmpty())          # Check whether RDD is empty\n",
        "print(rdd3.max())             # Maximum value of RDD elements\n",
        "print(rdd3.mean())            # Mean value of RDD elements\n",
        "print(rdd3.stdev())           # Standard Deviation (how dispersed the data is in relation to the mean.) of RDD elements\n",
        "print(rdd3.variance())        # Variance (Variance is the average squared deviations from the mean, while standard deviation is the square root of this number. ) value of RDD elements\n",
        "print(rdd3.stats())           # Summary statistics (count, mean, stdev, max & min)\n",
        "print(rdd3.histogram(3))      # Compute histogram by bins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkqQrf8urrux",
        "outputId": "7045644a-3445-4129-dc01-442bd9d0a2c6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n",
            "defaultdict(<class 'int'>, {'a': 1, 'b': 1, 'c': 1})\n",
            "defaultdict(<class 'int'>, {('a', 7): 1, ('b', 2): 1, ('c', 2): 1})\n",
            "{'a': 7, 'b': 2, 'c': 2}\n",
            "4950\n",
            "False\n",
            "99\n",
            "49.5\n",
            "28.86607004772212\n",
            "833.25\n",
            "(count: 100, mean: 49.5, stdev: 28.86607004772212, max: 99.0, min: 0.0)\n",
            "([0, 33, 66, 99], [33, 33, 34])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Functions"
      ],
      "metadata": {
        "id": "9nu7VrbwCkgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a function to each RDD element\n",
        "print(rdd.map(lambda x: (x[1],x[0])).collect()) # Inverse elements\n",
        "# Collect() is the function, operation for RDD or Dataframe that is used to retrieve the data from the Dataframe. It is used useful in retrieving all the elements of the row from each partition in an RDD and brings that over the driver node/program.\n",
        "\n",
        "# Apply a function to each RDD element and flatten the result\n",
        "print(rdd.flatMap(lambda x: (x[1],x[0])).collect())\n",
        "\n",
        "#Apply a flatMap function to each (key,value) pair of rdd4 without changing the keys\n",
        "print(rdd4.flatMapValues(lambda x: x).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5iFKpu42-6P",
        "outputId": "b2818d1f-9c7b-4661-adf1-6a45f0d5673d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(7, 'a'), (2, 'b'), (2, 'c')]\n",
            "[7, 'a', 2, 'b', 2, 'c']\n",
            "[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Data"
      ],
      "metadata": {
        "id": "KYxdPACIFKbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.collect()) # Return a list with all RDD elements\n",
        "print(rdd.take(2))   # Take first 2 RDD elements\n",
        "print(rdd.first())   # Take first element\n",
        "print(rdd.top(2))    # ASCII sorting of the top elememts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syHCMXl1CtJx",
        "outputId": "326e97cd-0a99-4857-98c8-b0af3dc33e3f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('x', 10), ('x', 11), ('y', 10), ('b', 2), ('c', 2)]\n",
            "[('x', 10), ('x', 11)]\n",
            "('x', 10)\n",
            "[('y', 10), ('x', 11)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return sampled subset of rdd3 sample(frac, seed)\n",
        "print(rdd3.sample(False, 0.15, 50).collect())\n",
        "print(rdd3.sample(False, 0.15, 10).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sds9YQF4FiAq",
        "outputId": "5aea1512-cc60-4ee0-90f4-63f5b9bfae12"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 10, 12, 17, 26, 29, 37, 61, 71, 72, 75, 86, 97, 98, 99]\n",
            "[5, 14, 19, 20, 21, 29, 33, 44, 45, 54, 55, 60, 64, 67, 81, 85, 86, 88, 95, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the RDD\n",
        "rdd.filter(lambda x: 'a' in x).collect()\n",
        "\n",
        "# Return distinct RDD values\n",
        "rdd.distinct().collect()\n",
        "\n",
        "# Return (key,value) RDD's keys\n",
        "rdd.keys().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na58Y301Gy47",
        "outputId": "b0aed575-2467-44c0-af66-7db166ff4172"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x', 'x', 'y', 'b', 'c']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a function to all RDD elements\n",
        "def g(x): print(x)\n",
        "rdd.foreach(g)"
      ],
      "metadata": {
        "id": "fgBCnPlhHtO4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping Data"
      ],
      "metadata": {
        "id": "JsCeqnudJpB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce\n",
        "print(rdd.reduceByKey(lambda x,y : x+y).collect()) # Merge the rdd values for each key \n",
        "print(rdd.reduce(lambda x,y : x+y))                # Merge the rdd values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebiFj6JjIVh8",
        "outputId": "52f1e752-a1a6-4ebf-be6e-835b3e5ad9c4"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4950, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group By\n",
        "print(rdd3.groupBy(lambda x: x %2).flatMapValues(list).collect()) # Return RDD of grouped values\n",
        "print(rdd.groupByKey().mapValues(list).collect())                 # Group rdd by key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk9by7yVoQ4L",
        "outputId": "6762e5df-2422-42b3-a57c-9a704c304ef6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0), (0, 2), (0, 4), (0, 6), (0, 8), (0, 10), (0, 12), (0, 14), (0, 16), (0, 18), (0, 20), (0, 22), (0, 24), (0, 26), (0, 28), (0, 30), (0, 32), (0, 34), (0, 36), (0, 38), (0, 40), (0, 42), (0, 44), (0, 46), (0, 48), (0, 50), (0, 52), (0, 54), (0, 56), (0, 58), (0, 60), (0, 62), (0, 64), (0, 66), (0, 68), (0, 70), (0, 72), (0, 74), (0, 76), (0, 78), (0, 80), (0, 82), (0, 84), (0, 86), (0, 88), (0, 90), (0, 92), (0, 94), (0, 96), (0, 98), (1, 1), (1, 3), (1, 5), (1, 7), (1, 9), (1, 11), (1, 13), (1, 15), (1, 17), (1, 19), (1, 21), (1, 23), (1, 25), (1, 27), (1, 29), (1, 31), (1, 33), (1, 35), (1, 37), (1, 39), (1, 41), (1, 43), (1, 45), (1, 47), (1, 49), (1, 51), (1, 53), (1, 55), (1, 57), (1, 59), (1, 61), (1, 63), (1, 65), (1, 67), (1, 69), (1, 71), (1, 73), (1, 75), (1, 77), (1, 79), (1, 81), (1, 83), (1, 85), (1, 87), (1, 89), (1, 91), (1, 93), (1, 95), (1, 97), (1, 99)]\n",
            "[('x', [10, 11]), ('y', [10]), ('b', [2]), ('c', [2])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregating\n",
        "seqOp = lambda x,y: (x[0]+y, x[1]+1)\n",
        "print(seqOp)\n",
        "combOp = lambda x,y: (x[0]+y[0], x[1]+y[1])\n",
        "print(combOp)\n",
        "print(rdd3.aggregate((0,0),seqOp,combOp)) # #Aggregate RDD elements of each partition and then the results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUiKXM0xJ-0L",
        "outputId": "92122085-6a40-4af2-bd66-3d44bd1030f3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function <lambda> at 0x7f5ffcc305f0>\n",
            "<function <lambda> at 0x7f5ffcc30ef0>\n",
            "(4950, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mathematical Operations"
      ],
      "metadata": {
        "id": "4EwL28smp4MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.subtract(rdd3).collect())       # return each rdd value not contained in rdd3\n",
        "print(rdd3.substractByKey(rdd).collect()) # return each (key, value) pair of rdd3 with no matching key in rdd\n",
        "print(rdd.cartesian(rdd3).collect()) # return the cartesian product of rdd and rdd#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJgwTwrzpQh0",
        "outputId": "135f18a8-5755-476d-9d96-af133aa03f0d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('x', 11), ('b', 2), ('c', 2), ('x', 10), ('y', 10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sort\n"
      ],
      "metadata": {
        "id": "kI3XDgsZrNLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.sortBy(lambda x : x[1]).collect())\n",
        "print(rdd.sortByKey().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBM3kXZPqPT1",
        "outputId": "428af930-7a90-4c20-a33d-4b8fc9bd1f93"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('b', 2), ('c', 2), ('x', 10), ('y', 10), ('x', 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repartitioning"
      ],
      "metadata": {
        "id": "wzJ-mcnlsZVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd.repartition(4))\n",
        "print(rdd.coalesce(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "458R9jyXr0Gi",
        "outputId": "4d97a22d-8456-4f89-be0d-605e4cf7734b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MapPartitionsRDD[365] at coalesce at NativeMethodAccessorImpl.java:0\n",
            "CoalescedRDD[366] at coalesce at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving"
      ],
      "metadata": {
        "id": "LUDgBd3Asy1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.saveAsTextFile('rdd.txt')\n",
        "#rdd.saveAsHadoopFile(\"hdfs://namenodehost/parent/child\",'org.apache.hadoop.mapred.TextOutputFormat')"
      ],
      "metadata": {
        "id": "-0yCoEyUsvgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopping Spark Context"
      ],
      "metadata": {
        "id": "7qas9IqCt07i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "6zm9Smv6tRAD"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "59rkeuaJt6yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%bash\n",
        "# ./bin/spark-submit examples/src/main/python/pi.py"
      ],
      "metadata": {
        "id": "u-cRURmTt56j"
      },
      "execution_count": 131,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "PySpark RDD Cheat Sheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6jh+r48eJ8M6XL94jfN1f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}